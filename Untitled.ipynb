{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "목록: \n",
      "['KOBIS_기생충.xlsx', 'KOBIS_맨인블랙.xlsx', 'KOBIS_보해미안_랩소디.xlsx', 'KOBIS_알라딘.xlsx', 'KOBIS_에이지_오브_울트론.xlsx', 'KOBIS_죄와벌.xlsx', 'KOBIS_주토피아.xlsx', '~$KOBIS_보해미안_랩소디.xlsx']\n",
      "읽으실려는 파일 이름을 입력해주세요 : KOBIS_보해미안_랩소디.xlsx\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "######### 파일 목록 불러오기\n",
    "path = \"./\"\n",
    "file_list = os.listdir(path)\n",
    "file_list_xlsx = [file for file in file_list if file.endswith(\".xlsx\")]\n",
    "\n",
    "print(\"목록: \")\n",
    "print(file_list_xlsx)\n",
    "\n",
    "filename = input(\"읽으실려는 파일 이름을 입력해주세요 : \")\n",
    "\n",
    "data = pd.read_excel(filename)\n",
    "\n",
    "\n",
    "########## 파일 데이터 불러오기\n",
    "\n",
    "dataX = []\n",
    "dataY = []\n",
    "index = 1\n",
    "\n",
    "for i in data['누적관객수']:\n",
    "    dataX.append(index)\n",
    "    dataY.append(i)\n",
    "    index+=1\n",
    "\n",
    "train_size = int(len(dataY) * 0.4)\n",
    "test_size = len(dataY) - train_size\n",
    "\n",
    "trainX = dataX[0:train_size]\n",
    "trainY = dataY[0:train_size]\n",
    "\n",
    "testX = dataX[train_size:len(dataX)]\n",
    "testY = dataY[train_size:len(dataY)]\n",
    "\n",
    "########### 인공지능 학습 시키기\n",
    "W = tf.Variable(tf.random_normal(shape = [1]),name = \"W\")\n",
    "b = tf.Variable(tf.random_normal(shape = [1]),name = \"b\")\n",
    "x = tf.placeholder(tf.float32,name = \"x\")\n",
    "\n",
    "### 범위\n",
    "max_diff_range = (testY[-1])//10\n",
    "epoch = 500000\n",
    "\n",
    "###\n",
    "linear_model = W*x+b\n",
    "\n",
    "y = tf.placeholder(tf.float32,name = \"y\")\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(linear_model-y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.001)\n",
    "train_step = optimizer.minimize(loss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "while True:\n",
    "    for i in range(epoch):\n",
    "        sess.run(train_step, feed_dict={x: trainX, y: trainY})\n",
    "\n",
    "    for i in range(test_size):\n",
    "        if abs(sess.run(linear_model,feed_dict={x:testX[i]}) - testY[i]) > max_diff_range:\n",
    "            print(i)\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\"\"\"\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(epoch):\n",
    "    sess.run(train_step,feed_dict={x:trainX, y:trainY})\n",
    "\n",
    "while True:\n",
    "    for i in range(test_size):\n",
    "        if abs(sess.run(linear_model, feed_dict={x: testX[i]}) - testY[i]) > max_diff_range:\n",
    "            #print(sess.run(linear_model, feed_dict={x: testX[i]}), testY[i] , abs(sess.run(linear_model, feed_dict={x: testX[i]}) - testY[i]))\n",
    "            trainX.append(testX.pop(0))\n",
    "            trainY.append(testY.pop(0))\n",
    "            test_size = len(testY)\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "    for step in range(epoch):\n",
    "        sess.run(train_step, feed_dict={x: trainX, y: trainY})\n",
    "\n",
    "########## 결과값 내기\n",
    "x_test = [index]\n",
    "\n",
    "print(\"지금으로부터 1일 후의 예상 누적관객수는 %d 입니다\"%(sess.run(linear_model,feed_dict={x:x_test})))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX = []\n",
    "dataY = []\n",
    "index = 1\n",
    "\n",
    "for i in data['누적관객수']:\n",
    "    dataX.append(i)\n",
    "    dataY.append(index)\n",
    "    index+=1\n",
    "train_size = int(len(dataY) * 0.7)\n",
    "test_size = len(dataY) - train_size\n",
    "\n",
    "trainX = np.array(dataX[0:train_size])\n",
    "trainY = np.array(dataY[0:train_size])\n",
    "\n",
    "testX = np.array(dataX[train_size:len(dataX)])\n",
    "testY = np.array(dataY[train_size:len(dataY)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(dataY) * 0.7)\n",
    "test_size = len(dataY) - train_size\n",
    "\n",
    "trainX = np.array(dataX[0:train_size])\n",
    "trainY = np.array(dataY[0:train_size])\n",
    "\n",
    "testX = np.array(dataX[train_size:len(dataX)])\n",
    "testY = np.array(dataY[train_size:len(dataY)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = tf.placeholder(tf.float32,[None,1])\n",
    "predictions = tf.placeholder(tf.float32,[None,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-1-deaa96e78ae3>:10: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-7-75458a90f915>:1: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    }
   ],
   "source": [
    "multi_cells = tf.contrib.rnn.MultiRNNCell([lstm_cell() for _ in range(1)], state_is_tuple = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-7dd44ee46786>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhypothesis\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmulti_cells\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[1;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[0;32m    620\u001b[0m       \u001b[1;31m# (B,T,D) => (T,B,D)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m       \u001b[0mflat_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0minput_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mflat_input\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 622\u001b[1;33m       \u001b[0mflat_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_transpose_batch_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0minput_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mflat_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m     \u001b[0mparallel_iterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparallel_iterations\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    620\u001b[0m       \u001b[1;31m# (B,T,D) => (T,B,D)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m       \u001b[0mflat_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0minput_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mflat_input\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 622\u001b[1;33m       \u001b[0mflat_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_transpose_batch_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0minput_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mflat_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m     \u001b[0mparallel_iterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparallel_iterations\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m_transpose_batch_time\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     65\u001b[0m   x_t.set_shape(\n\u001b[0;32m     66\u001b[0m       tensor_shape.TensorShape([\n\u001b[1;32m---> 67\u001b[1;33m           \u001b[0mx_static_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_static_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m       ]).concatenate(x_static_shape[2:]))\n\u001b[0;32m     69\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mx_t\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "hypothesis, _states = tf.nn.dynamic_rnn(multi_cells,X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = tf.contrib.layers.fully_connected(hypothesis[:-1],output_dim,activation_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_sum(tf.square(Y_pred - Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = tf.sqrt(tf.reduce_mean(tf.squared_difference(targets, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(epoch_num):\n",
    "        sess.run(train,feed_dict = {X:trainX,Y:trainY})\n",
    "\n",
    "    test_predict = sess.run(Y_pred, feed_dict={X: testX})\n",
    "\n",
    "    rmse_val = sess.run(rmse, feed_dict={targets:testY,predictions:test_predict})\n",
    "\n",
    "    plt.plot(testY,'r')\n",
    "    plt.plot(test_predict,'b')\n",
    "    plt.xlabel(\"Time Period\")\n",
    "    plt.ylabel(\"Accumulated Attendance\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
